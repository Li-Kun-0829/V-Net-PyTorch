{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8986ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "from PIL import Image\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join, splitext\n",
    "import torch.utils.data\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ff07b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    # record the running time\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "    \n",
    "    def start(self):\n",
    "        self.tik = time.time()\n",
    "        \n",
    "    def stop(self):\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "    \n",
    "    def avg(self):\n",
    "        return sum(self.times)/len(self.times)\n",
    "    \n",
    "    def sum(self):\n",
    "        return sum(self.times)\n",
    "    \n",
    "    def cumsum(self):\n",
    "        return np.array(self.times).cumsum().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c725d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(i = 0):\n",
    "    # if the gpu exist in PC, it will return gpu(i), otherwise return cpu()\n",
    "    if torch.cuda.device_count() >= i+1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiceCo(X,y):\n",
    "    intersection = (X*y).sum()\n",
    "    union1 = X.sum() + y.sum()\n",
    "    DiceFactor = (2*intersection)/(union1)\n",
    "    return DiceFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6022e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_gpu(model, data_iter, device=None):\n",
    "    if isinstance(model, nn.Module):\n",
    "        model.eval()\n",
    "        if not device:\n",
    "            device = next(iter(model.parameters())).device\n",
    "    metric = Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(DiceCo(model(X),y), 1)\n",
    "    return metric[0]/metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de71965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    numerator = 2*((y_hat*y).sum())\n",
    "    return float(numerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "    #在n个变量上累加\n",
    "    def __init__(self,n):\n",
    "        self.data = [0.0]*n\n",
    "    \n",
    "    def add(self, *args):\n",
    "        self.data = [a+float(b) for a,b in zip(self.data, args)]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.data = [0.0]*len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b047c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_xlim(xlim)\n",
    "    axes.set_ylim(ylim)\n",
    "    axes.set_xscale(xscale)\n",
    "    axes.set_yscale(yscale)\n",
    "    if legend:\n",
    "        axes.legend(legend)\n",
    "    axes.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animator:\n",
    "    #在动画中绘制数据\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None, ylim=None, xscale='linear', yscale='linear',fmts=('-','m--','g-.','r:'),nrows=1,ncols=1,figsize=(5,3)):\n",
    "        #增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        self.fig, self.axes = plt.subplots(nrows,ncols,figsize=(5,3))\n",
    "        if nrows*ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        #使用lambda函数捕获参数\n",
    "        self.config_axes = lambda: set_axes(self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None,None,fmts\n",
    "\n",
    "    \n",
    "    def add(self, x, y):\n",
    "        #向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x]*n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x,y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b) \n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath=os.getcwd()\n",
    "\n",
    "params = dict()\n",
    "params['DataManagerParams']=dict()\n",
    "params['ModelParams']=dict()\n",
    "\n",
    "#params of the algorithm\n",
    "params['ModelParams']['dirTrain']=os.path.join(basePath,'training_data')\n",
    "params['ModelParams']['dirTest']=os.path.join(basePath,'test_data')\n",
    "params['ModelParams']['dirResult']=os.path.join(basePath,'Results') #where we need to save the results (relative to the base path)\n",
    "\n",
    "#params of the DataManager\n",
    "params['DataManagerParams']['dstRes'] = np.asarray([1,1,1.5],dtype=float)\n",
    "params['DataManagerParams']['VolSize'] = np.asarray([128,128,64],dtype=int)\n",
    "params['DataManagerParams']['normDir'] = False #if rotates the volume according to its transformation in the mhd file. Not reccommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6981f183",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager(object):\n",
    "    params = None\n",
    "    srcFolder = None\n",
    "    resultsDir = None\n",
    "    \n",
    "    fileList = None\n",
    "    gtList = None\n",
    "    \n",
    "    sitkImages = None\n",
    "    sitkGT = None\n",
    "    meanIntensityTrain = None\n",
    "    \n",
    "    def __init__(self, srcFolder, resultsDir, parameters):\n",
    "        self.params = parameters\n",
    "        self.srcFolder = srcFolder\n",
    "        self.resultsDir = resultsDir\n",
    "        \n",
    "    def createImageFileList(self):\n",
    "        self.fileList = [f for f in listdir(self.srcFolder) if isfile(join(self.srcFolder, f)) and 'segmentation' not in f and 'raw' not in f]\n",
    "        print('FILE LIST: ' + str(self.fileList))\n",
    "    \n",
    "    def createGTFileList(self):\n",
    "        self.gtList = list()\n",
    "        for f in self.fileList:\n",
    "            filename, ext = splitext(f)\n",
    "            self.gtList.append(join(filename + '_segmentation' + ext))\n",
    "        print('GT LIST: ' + str(self.gtList))\n",
    "            \n",
    "    def loadImages(self):\n",
    "        self.sitkImages = dict()\n",
    "        rescalFilt = sitk.RescaleIntensityImageFilter()\n",
    "        rescalFilt.SetOutputMaximum(1)\n",
    "        rescalFilt.SetOutputMinimum(0)\n",
    "        \n",
    "        stats = sitk.StatisticsImageFilter()\n",
    "        m = 0.\n",
    "        for f in self.fileList:\n",
    "            self.sitkImages[f] = rescalFilt.Execute(sitk.Cast(sitk.ReadImage(join(self.srcFolder, f)), sitk.sitkFloat32))\n",
    "            stats.Execute(self.sitkImages[f])\n",
    "            m += stats.GetMean()\n",
    "        self.meanIntensityTrain = m/len(self.sitkImages)\n",
    "        \n",
    "    def loadGT(self):\n",
    "        self.sitkGT = dict()\n",
    "        for f in self.gtList:\n",
    "            self.sitkGT[f] = sitk.Cast(sitk.ReadImage(join(self.srcFolder, f))>0.5, sitk.sitkFloat32)\n",
    "            \n",
    "    def loadTrainingData(self):\n",
    "        self.createImageFileList()\n",
    "        self.createGTFileList()\n",
    "        self.loadImages()\n",
    "        self.loadGT()\n",
    "        \n",
    "    def loadTestData(self):\n",
    "        self.createImageFileList()\n",
    "        self.loadImages()\n",
    "        \n",
    "    def getNumpyImages(self):\n",
    "        dat = self.getNumpyData(self.sitkImages, sitk.sitkLinear)\n",
    "        return dat\n",
    "    \n",
    "    def getNumpyGT(self):\n",
    "        dat = self.getNumpyData(self.sitkGT, sitk.sitkLinear)\n",
    "        for key in dat:\n",
    "            dat[key] = (dat[key]>0.5).astype(dtype = np.float32)\n",
    "        return dat\n",
    "    \n",
    "    def getNumpyData(self, dat, method):\n",
    "        ret = dict()\n",
    "        for key in dat:\n",
    "            ret[key] = np.zeros([self.params['VolSize'][0], self.params['VolSize'][1], self.params['VolSize'][2]], dtype = np.float32)\n",
    "            img = dat[key]\n",
    "            #we rotate the image according to its transformation using the direction and according to the final spacing we want\n",
    "            factor = np.asarray(img.GetSpacing()) / np.asarray(self.params['dstRes'])\n",
    "            factorSize = np.asarray(img.GetSize() * factor, dtype = float)\n",
    "            newSize = np.max([factorSize, self.params['VolSize']], axis = 0)\n",
    "            newSize = newSize.astype(dtype=int)\n",
    "            \n",
    "            T = sitk.AffineTransform(3)\n",
    "            T.SetMatrix(img.GetDirection())\n",
    "            \n",
    "            resampler = sitk.ResampleImageFilter()\n",
    "            resampler.SetReferenceImage(img)\n",
    "            resampler.SetOutputSpacing([self.params['dstRes'][0], self.params['dstRes'][1], self.params['dstRes'][2]])\n",
    "            resampler.SetSize(newSize.tolist())\n",
    "            resampler.SetInterpolator(method)\n",
    "            if self.params['normDir']:\n",
    "                resampler.SetTransform(T.GetInverse())\n",
    "            imgResampled = resampler.Execute(img)\n",
    "            imgCentroid = np.asarray(newSize, dtype = float) / 2.0\n",
    "            imgStartPx = (imgCentroid - self.params['VolSize']/2.0).astype(dtype = int)\n",
    "            regionExtractor = sitk.RegionOfInterestImageFilter()\n",
    "            regionExtractor.SetSize(self.params['VolSize'].astype(dtype = int).tolist())\n",
    "            regionExtractor.SetIndex(imgStartPx.tolist())\n",
    "            imgResampledCropped = regionExtractor.Execute(imgResampled)\n",
    "            ret[key] = np.transpose(sitk.GetArrayFromImage(imgResampledCropped).astype(dtype=float), [2,1,0]) #dimension transformation for transverse/sagittal/coronal\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc23416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define here a data manage object for Training\n",
    "dataManagerTrain = DataManager(params['ModelParams']['dirTrain'],\n",
    "                               params['ModelParams']['dirResult'],\n",
    "                               params['DataManagerParams'])\n",
    "\n",
    "dataManagerTrain.loadTrainingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e98f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "howManyImages_forTraining = len(dataManagerTrain.sitkImages)\n",
    "howManyGT_forTraining = len(dataManagerTrain.sitkGT)\n",
    "\n",
    "assert howManyGT_forTraining == howManyImages_forTraining\n",
    "\n",
    "print(\"The dataset has shape: data - \" + str(howManyImages_forTraining) + \". labels - \" + str(howManyGT_forTraining))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149a8c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyImages_Train = dataManagerTrain.getNumpyImages()\n",
    "numpyGT_Train = dataManagerTrain.getNumpyGT()\n",
    "\n",
    "for key in numpyImages_Train:\n",
    "    mean_Train = np.mean(numpyImages_Train[key][numpyImages_Train[key]>0])\n",
    "    std_Train = np.std(numpyImages_Train[key][numpyImages_Train[key]>0])\n",
    "\n",
    "    numpyImages_Train[key]-=mean_Train\n",
    "    numpyImages_Train[key]/=std_Train\n",
    "\n",
    "tensorImages_Train = {key: torch.tensor(value).float() for key, value in numpyImages_Train.items()}\n",
    "tensorGT_Train = {key: torch.tensor(value).float() for key, value in numpyGT_Train.items()}\n",
    "\n",
    "merged_tensorImages_Train = torch.stack(list(tensorImages_Train.values()))\n",
    "merged_tensorGT_Train = torch.stack(list(tensorGT_Train.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e94142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define here a data manage object for Test\n",
    "dataManagerTest = DataManager(params['ModelParams']['dirTest'],\n",
    "                               params['ModelParams']['dirResult'],\n",
    "                               params['DataManagerParams'])\n",
    "\n",
    "dataManagerTest.loadTrainingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f06b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "howManyImages_forTest = len(dataManagerTest.sitkImages)\n",
    "howManyGT_forTest = len(dataManagerTest.sitkGT)\n",
    "\n",
    "assert howManyGT_forTest == howManyImages_forTest\n",
    "\n",
    "print(\"The dataset has shape: data - \" + str(howManyImages_forTest) + \". labels - \" + str(howManyGT_forTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e24166",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyImages_Test = dataManagerTest.getNumpyImages()\n",
    "numpyGT_Test = dataManagerTest.getNumpyGT()\n",
    "\n",
    "for key in numpyImages_Test:\n",
    "    mean_Test = np.mean(numpyImages_Test[key][numpyImages_Test[key]>0])\n",
    "    std_Test = np.std(numpyImages_Test[key][numpyImages_Test[key]>0])\n",
    "\n",
    "    numpyImages_Test[key]-=mean_Test\n",
    "    numpyImages_Test[key]/=std_Test\n",
    "\n",
    "tensorImages_Test = {key: torch.tensor(value).float() for key, value in numpyImages_Test.items()}\n",
    "tensorGT_Test = {key: torch.tensor(value).float() for key, value in numpyGT_Test.items()}\n",
    "\n",
    "merged_tensorImages_Test = torch.stack(list(tensorImages_Test.values()))\n",
    "merged_tensorGT_Test = torch.stack(list(tensorGT_Test.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc06358",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dataset_Train = torch.utils.data.TensorDataset(merged_tensorImages_Train, merged_tensorGT_Train)\n",
    "\n",
    "torch_dataset_Test = torch.utils.data.TensorDataset(merged_tensorImages_Test, merged_tensorGT_Test)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "train_iter = torch.utils.data.DataLoader(\n",
    "    dataset = torch_dataset_Train,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    #num_works = 2,\n",
    ")\n",
    "\n",
    "test_iter = torch.utils.data.DataLoader(\n",
    "    dataset = torch_dataset_Test,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False,\n",
    "    #num_works = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c57d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X, Y):\n",
    "    X_sm = (torch.exp(Y))/(torch.exp(X)+torch.exp(Y))\n",
    "    return X_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16101218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, input_channels, num_channels, use_1x1conv = False, strides = 1, shortcuts = 1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(input_channels, num_channels, kernel_size = 5, padding = 2, stride = strides)\n",
    "        \n",
    "        if shortcuts == 2:\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.PReLU(),\n",
    "                nn.Conv3d(num_channels, num_channels, kernel_size = 5, padding = 2, stride = 1))\n",
    "            self.conv3 = None\n",
    "        elif shortcuts == 3:\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.PReLU(),\n",
    "                nn.Conv3d(num_channels, num_channels, kernel_size = 5, padding = 2, stride = 1))\n",
    "            self.conv3 = nn.Sequential(\n",
    "                nn.PReLU(),\n",
    "                nn.Conv3d(num_channels, num_channels, kernel_size = 5, padding = 2, stride = 1))\n",
    "        else:\n",
    "            self.conv2 = None\n",
    "            self.conv3 = None\n",
    "        \n",
    "        if use_1x1conv:\n",
    "            self.conv4 = nn.Conv3d(input_channels, num_channels, kernel_size = 1, stride = strides)\n",
    "        else:\n",
    "            self.conv4 = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        Y = self.conv1(X)\n",
    "        \n",
    "        if self.conv2 and self.conv3 == None:\n",
    "            Y = self.conv2(Y)\n",
    "        elif self.conv2 and self.conv3:\n",
    "            Y = self.conv2(Y)\n",
    "            Y = self.conv3(Y)\n",
    "        \n",
    "        if self.conv4:\n",
    "            X = self.conv4(X)\n",
    "        \n",
    "        Y += X\n",
    "        \n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab8276",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = Residual(1, 16, use_1x1conv = True)\n",
    "b2 = Residual(input_channels = 32, num_channels = 32)\n",
    "b3 = Residual(input_channels = 64, num_channels = 64, shortcuts = 2)\n",
    "b4 = Residual(input_channels = 128, num_channels = 128, shortcuts = 3)\n",
    "b5 = Residual(input_channels = 256, num_channels = 256, shortcuts = 3)\n",
    "b6 = Residual(input_channels = 128, num_channels = 128, shortcuts = 2)\n",
    "b7 = Residual(input_channels = 64, num_channels = 64, shortcuts = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1623e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EndToEndModel(nn.Module):\n",
    "    def __init__(self, in_channel):\n",
    "        super(EndToEndModel, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            b1,\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 16, out_channels = 32, kernel_size = 2, padding = 0, stride = 2),\n",
    "            nn.PReLU(),\n",
    "            b2,\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 32, out_channels = 64, kernel_size = 2, padding = 0, stride = 2),\n",
    "            nn.PReLU(),\n",
    "            b3,\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 64, out_channels = 128, kernel_size = 2, padding = 0, stride = 2),\n",
    "            nn.PReLU(),\n",
    "            b4,\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 128, out_channels = 256, kernel_size = 2, padding = 0, stride = 2),\n",
    "            nn.PReLU(),\n",
    "            b5,\n",
    "            nn.PReLU(),\n",
    "            nn.ConvTranspose3d(in_channels = 256, out_channels = 128, kernel_size = 2, stride = 2),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer6 = nn.Sequential(\n",
    "            b5,\n",
    "            nn.PReLU(),\n",
    "            nn.ConvTranspose3d(in_channels = 256, out_channels = 64, kernel_size = 2, padding = 0, stride = 2),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer7 = nn.Sequential(\n",
    "            b6,\n",
    "            nn.PReLU(),\n",
    "            nn.ConvTranspose3d(in_channels = 128, out_channels = 32, kernel_size = 2, padding = 0, stride = 2),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer8 = nn.Sequential(\n",
    "            b7,\n",
    "            nn.PReLU(),\n",
    "            nn.ConvTranspose3d(in_channels = 64, out_channels = 16, kernel_size = 2, padding = 0, stride = 2),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer9 = nn.Sequential(\n",
    "            b2,\n",
    "            nn.PReLU(),\n",
    "            nn.Conv3d(in_channels = 32, out_channels = 2, kernel_size = 5, padding = 2, stride = 1),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv3d(in_channels = 2, out_channels = 2, kernel_size = 1, stride = 1),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        y1 = x\n",
    "        x = self.layer2(x)\n",
    "        y2 = x\n",
    "        x = self.layer3(x)\n",
    "        y3 = x\n",
    "        x = self.layer4(x)\n",
    "        y4 = x\n",
    "        x = self.layer5(x)\n",
    "        x = torch.cat((x,y4),dim = 0)\n",
    "        x = self.layer6(x)\n",
    "        x = torch.cat((x,y3),dim = 0)\n",
    "        x = self.layer7(x)\n",
    "        x = torch.cat((x,y2),dim = 0)\n",
    "        x = self.layer8(x)\n",
    "        x = torch.cat((x,y1),dim = 0)\n",
    "        x = self.layer9(x)\n",
    "        x = softmax(X = x[0, :, :, :], Y = x[1, :, :, :])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206c346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EndToEndModel(1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b94583",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dice_loss(nn.Module):\n",
    "    def __init__(self, smooth = 0.01):\n",
    "        super(dice_loss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        denominator_1 = (pred**2).sum()\n",
    "        denominator_2 = (target**2).sum()\n",
    "        union = denominator_1+denominator_2\n",
    "        numerator = 2*((pred*target).sum())\n",
    "        dice_coefficient = (numerator + self.smooth)/(union + self.smooth)\n",
    "        #dice_coefficient = (numerator)/(union)\n",
    "        loss = 1-dice_coefficient\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2f4048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def msra_init(module: nn.Module):\n",
    "    if isinstance(module, (nn.Conv2d, nn.ConvTranspose2d, nn.Conv3d, nn.ConvTranspose3d)):\n",
    "        nn.init.kaiming_normal_(module.weight.data)\n",
    "        if module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "    elif isinstance(module, (nn.Linear)):\n",
    "        nn.init.kaiming_uniform_(module.weight.data)\n",
    "        if module.bias is not None:\n",
    "            module.bias.data.zero()\n",
    "    elif isinstance(module, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
    "        module.weight.data.normal_(1.0, 0.02)\n",
    "        module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71387fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_iter, test_iter, num_epochs, lr, device):\n",
    "    def init_weights(m):\n",
    "        for m in model.modules():\n",
    "            msra_init(m)\n",
    "        init.constant_(model.layer1[0].conv4.weight, 1)\n",
    "    model.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = lr, momentum = 0.9)\n",
    "    loss = dice_loss()\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], legend=['train loss', 'train acc', 'test acc'])\n",
    "    timer, num_batches = Timer(), len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        metric = Accumulator(3)\n",
    "        model.train()\n",
    "        for i, (X,y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            y_hat = model(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            #print(model.layer9[4].weight)\n",
    "            #print(y_hat)\n",
    "            with torch.no_grad():\n",
    "                metric.add(l, accuracy(y_hat, y)/X.numel(), 1)\n",
    "            timer.stop()\n",
    "            train_l = metric[0]/metric[2]\n",
    "            train_acc = metric[1]/metric[2]\n",
    "            #metric.reset()\n",
    "            if (i+1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i+1) / num_batches, (train_l, train_acc, None))\n",
    "        test_acc = evaluate_accuracy_gpu(model, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    print(f'loss{train_l:.3f}, train acc {train_acc:.3f},' f'test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2]*num_epochs/timer.sum():.1f} examples/sec ' f'on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd7f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs = 0.0005, 30\n",
    "train(model, train_iter, test_iter, num_epochs, lr, try_gpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
